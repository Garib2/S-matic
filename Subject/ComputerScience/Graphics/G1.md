---
layout: content
title: Rendering Pipieline
permalink: /info/CS/Numerical/G1.md/
---
## 0.1 그래픽 처리기
1. OpenGL 라이브러리 가 정의하는 10종의 그래픽 기본도형들
- 점들
- 선들 / 선띠 / 선 루프
- 삼각형 들 / 삼각형 띠 / 삼각형 부채
- 사각형 / 사각형 띠 / 다각형


2. CPU와 독립적으로 명령을 수행하는 GPU
- CPU에서 GPU로 렌더링 명령을 보내면 GPU가 수행
- 비동기적인 작동으로 그동안 CPU는 다른작업이 가능
- OPENGL의 인터페이스를 하드웨어 추상층(HAL) 이라고 부름
- OPENGL의 함수들을 직접 구현하면 렌더링 명령 제출의 추가부담이 최소화된다

3. 3차원 그래픽카드
- VRAM은 GPU 상의 RAM
- 이미지버퍼들, 깊이/스텐실버퍼, 텍스쳐맵들이 포함됨
- 전면 이미지 버퍼= 뷰포트 렌더링 이미지 영역
- 후면 이미지 버퍼= GPU가 실제로 장면을 그리는곳
- 이미지가 완전히 렌더링 되면 후면 버퍼와 전면 버퍼가 교체(buffer swap)
- 깊이(z) 버퍼 = 화면 안쪽으로 얼마나 멀리 있는가(이미 존재하는 픽셀보다 더깊은 픽셀은 그리지 않음)
- 스텐실 버퍼(옵션) = 이미지 버퍼 안의 각 필셀에 대한 정수 마스크(픽셀 단위의 렌더링을 활성화 / 비활성화 제어)
- 텍스쳐맵들이 가장 메모리를 많이 차지함

## 02. 정점 변환
1. 기하데이터가 GPU에 전달
- 2차원 뷰포트에 그리기 위해 필요한 기하학적 변환들을 수행
- 물체공간/ 모델-뷰 변환 / 카메라공간_투영 / 동차절단공간_뷰포트변환 / 윈도우 공간
- 물체공간: 모형에만 쓰이는 좌표계
- 세계공간: 모형의 실제 위치와 방향이 저장된 좌표계(전역적임)
- 카메라 공간: x와 y축이 화면 디스플레이와 정렬되며 z축은 시선방향과 평행한 좌표계(eye space라고 부름)

2. 모델- 뷰 변환/ 투영 변환 / 동차 절단 공간 / NVC / 뷰포트 변환 / 윈도우 공간
모델-뷰 변환 (Model-View Transformation)

물체 공간(Object Space)을 세계 공간(World Space)으로 변환하고, 세계 공간을 카메라(뷰) 공간(Camera Space)으로 변환하는 행렬의 결합입니다. 이 결합된 변환을 MVP(모델-뷰-투영) 행렬이라고 합니다. 이 과정을 통해 물체의 위치, 회전, 크기 등이 반영됩니다.
투영 변환 (Projection Transformation)

카메라 공간에서 변환된 정점들을 동차 공간(Homogeneous Space)으로 변환합니다. 원근 투영의 경우, 원근감을 반영하여 정점들이 화면의 깊이와 크기에 맞게 변형됩니다.
동차 절단 공간 (Clipping in Homogeneous Space)

동차 공간 내에서 NDC(Normalized Device Coordinates)로 변환되기 전, 뷰 포인트에 따라 클리핑(자르기)을 수행합니다. 카메라의 시야(FOV)에 들어오는 정점들만 렌더링에 사용됩니다.
NDC 변환 (Normalization)

클리핑된 정점들을 [-1, 1] 범위로 정규화하여 NDC 공간으로 변환합니다. 이 과정에서 화면의 폭과 높이를 기준으로 비율이 조정됩니다.
뷰포트 변환 (Viewport Transformation)

NDC 공간의 좌표를 뷰포트(Viewport) 공간으로 변환합니다. 이때 정규화된 좌표를 화면 해상도에 맞추어 실제 픽셀 단위로 변환하고, 깊이 값도 윈도우 좌표 범위로 스케일링합니다.
윈도우 공간 (Window Space)

뷰포트 변환을 거친 후, 좌표들이 화면의 픽셀 좌표(윈도우 공간)로 표현됩니다. 이 좌표를 기반으로 렌더링 시스템이 픽셀을 화면에 출력합니다.

## 03. 래스터화와 단편 연산
1. 래스터화 (Rasterization)
정점 데이터에서 픽셀 데이터로 변환: 3D 공간의 정점(vertex) 데이터를 2D 화면의 픽셀(pixel) 데이터로 변환합니다. 여기서, MVP 행렬을 통해 클립 공간으로 변환된 정점들이 화면 공간에 대응되며, 이 과정에서 정점들은 삼각형으로 구성됩니다.
삼각형 세분화: 클립 공간에서의 삼각형들이 화면에 표시되도록 세분화하여 픽셀 단위로 나누고, 각 픽셀의 위치와 색상을 결정합니다.
렌더 타깃 설정: 이러한 픽셀들은 프레임 버퍼에 저장되고, 이후 단계에서 GPU가 처리하는 단위가 됩니다.
2. 프래그먼트 셰이더 실행 (Fragment Shader Execution)
각 프래그먼트(단편)에 대한 연산: 화면에 그릴 각 픽셀(단편)에 대해 색상, 텍스처, 라이팅(조명) 효과 등을 계산합니다. Blender에서는 이 과정을 셰이더 코드를 통해 처리하며, 각 픽셀에 대한 다양한 특성(예: 텍스처 매핑, 그림자 효과 등)을 반영합니다.
깊이 검사(Depth Test): 프래그먼트 셰이더에서 계산된 픽셀의 깊이 값을 이용해, 해당 픽셀이 현재 화면의 다른 픽셀 앞에 위치한 경우에만 렌더링합니다.
블렌딩(Blending): 투명도 또는 반투명 효과가 필요한 경우, 기존 화면의 픽셀 값과 새로 계산된 픽셀 값을 혼합하여 최종 픽셀 값을 계산합니다.
3. 출력 병합(Output Merge)
최종 출력: 각 단편의 연산이 완료된 후, 결과는 프레임 버퍼에 저장되고 화면에 출력됩니다. 이 과정에서는 여러 개의 출력 타깃(렌더 타깃)을 사용하여, 그림자 맵핑이나 반사/굴절 효과와 같은 추가적인 렌더링을 병합할 수 있습니다.
